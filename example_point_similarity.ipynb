{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b155ea17",
   "metadata": {},
   "source": [
    "# Point-to-Mesh Similarity Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load two meshes\n",
    "2. Specify a particular point on the source mesh\n",
    "3. Color-map the target mesh based on similarity to that point\n",
    "\n",
    "The analysis uses diffusion features + DINO features to compute semantic similarity between mesh vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc6797",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930249c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixiliu/miniforge3/envs/diff3f_copy2/lib/python3.10/site-packages/accelerate/utils/torch_xla.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from time import time\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors, generate_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from diffusion import init_pipe\n",
    "from dino import init_dino\n",
    "from functional_map import compute_surface_map\n",
    "import importlib\n",
    "import meshplot as mp\n",
    "from point_to_mesh_similarity import run_point_similarity_analysis, point_similarity_colormap, visualize_point_similarity, run_multi_point_correspondence_analysis\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91398f0c",
   "metadata": {},
   "source": [
    "## 2. Initialize Models\n",
    "\n",
    "This step loads the diffusion pipeline and DINO model for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394b3ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing diffusion pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixiliu/miniforge3/envs/diff3f_copy2/lib/python3.10/site-packages/diffusers/configuration_utils.py:239: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'unet_2d_condition.UNet2DConditionModel'>.load_config(...) followed by <class 'unet_2d_condition.UNet2DConditionModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c68df7997c44313b3a12433c20ddbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DINO model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing diffusion pipeline...\")\n",
    "pipe = init_pipe(device)\n",
    "\n",
    "print(\"Initializing DINO model...\")\n",
    "dino_model = init_dino(device)\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19f72e",
   "metadata": {},
   "source": [
    "## 3. Load Meshes\n",
    "\n",
    "Load your source and target meshes. You can modify the paths below to use your own meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc0c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source mesh: 11799 vertices, 23334 faces\n",
      "Target mesh: 9041 vertices, 17850 faces\n"
     ]
    }
   ],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_bottle_decomp.obj\"\n",
    "\n",
    "source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6403ea",
   "metadata": {},
   "source": [
    "## 4. Preview Meshes\n",
    "\n",
    "Let's visualize the meshes before analysis to get familiar with their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebd9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Preview the meshes side by side\n",
    "    d = mp.subplot(source_mesh.vert[:,0:3], source_mesh.face, s=[2, 2, 0])\n",
    "    mp.subplot(target_mesh.vert[:,0:3], target_mesh.face, s=[2, 2, 1], data=d)\n",
    "    print(\"Left: Source mesh | Right: Target mesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bd759",
   "metadata": {},
   "source": [
    "## 5. Configure Analysis Parameters\n",
    "\n",
    "Set up the parameters for the similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35136983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Configuration:\n",
      "- Text prompt: 'a beaker'\n",
      "- Number of views: 10\n"
     ]
    }
   ],
   "source": [
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "print(f\"\\nAnalysis Configuration:\")\n",
    "print(f\"- Text prompt: '{prompt}'\")\n",
    "print(f\"- Number of views: {num_views}\")\n",
    "\n",
    "\n",
    "p1 = [ 0.00886742, -0.04124315, -0.01754964]\n",
    "p2 = [-0.01223545,  0.0363251 ,  0.00719686]\n",
    "p3 = [-0.01694481,  0.03424783, -0.01735426]\n",
    "p4 = [-0.01596961,  0.03464369, -0.02075735]\n",
    "source_points_3d = np.array([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4aa161-dabf-4e8b-867b-e11c3f953c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71a170a4-1177-43fa-ade4-f98c9d372ada",
   "metadata": {},
   "source": [
    "### To clean up meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39690e47-00b5-4bb3-8767-f8cbc3b7696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    from utils import clean_obj_file_format_only\n",
    "    source_fixed = clean_obj_file_format_only(\"meshes/oakink_beaker_decomp2.obj\")\n",
    "    target_fixed = clean_obj_file_format_only(\"meshes/oakink_mug_decomp2.obj\")\n",
    "    \n",
    "    # Now load the new target mesh with your MeshContainer\n",
    "    source_mesh_path = \"meshes/oakink_beaker_decomp2_fixed.obj\"\n",
    "    target_mesh_path = \"meshes/oakink_mug_decomp2_fixed.obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19acdd5-f2a8-4275-8aab-470696bc852f",
   "metadata": {},
   "source": [
    "### To clean up GPU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4be742-bdd9-4697-9013-57105d5b9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import torch\n",
    "    \n",
    "    # Clear cache of unused memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Optionally, collect unused memory from Python garbage collector\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77549fde-a90f-40d8-8d5c-17e139e737b3",
   "metadata": {},
   "source": [
    "# Explore Re-mesh Open3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d3766-d453-4157-a45a-c17e7aac7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    mesh = o3d.io.read_triangle_mesh(target_mesh_path)\n",
    "    \n",
    "    # Create a point cloud with a uniform density using Poisson disk sampling\n",
    "    # The number_of_points parameter controls the point density.\n",
    "    # A higher number will result in a finer, more detailed final mesh.\n",
    "    pcd = mesh.sample_points_poisson_disk(number_of_points=10000)\n",
    "    \n",
    "    # Optional: Visualize the point cloud to inspect the distribution\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    # The alpha parameter controls the size of the spheres used to create the mesh.\n",
    "    # A smaller alpha will produce a tighter mesh that follows the point cloud more closely,\n",
    "    # while a larger alpha will create a coarser mesh.\n",
    "    alpha = 0.005\n",
    "    new_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\n",
    "    \n",
    "    # Compute vertex normals for correct lighting and shading\n",
    "    new_mesh.compute_vertex_normals()\n",
    "    \n",
    "    # Visualize the new mesh\n",
    "    o3d.visualization.draw_geometries([new_mesh], mesh_show_back_face=True)\n",
    "    \n",
    "    # Optional: Save the new mesh\n",
    "    # o3d.io.write_triangle_mesh(\"uniform_remeshed.ply\", new_mesh)\n",
    "\n",
    "    # Convert mesh to LineSet (wireframe representation)\n",
    "    wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(new_mesh)\n",
    "    wireframe.paint_uniform_color([0, 0, 0])  # black wireframe\n",
    "    \n",
    "    # Show wireframe\n",
    "    o3d.visualization.draw_geometries([wireframe])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7dd12e",
   "metadata": {},
   "source": [
    "## 6. Run Similarity Analysis\n",
    "\n",
    "This is the main computation step. It will:\n",
    "1. Extract features for both meshes using multiple camera views\n",
    "2. Compute similarity between the specified source point and all target vertices\n",
    "3. Generate the visualization\n",
    "\n",
    "⚠️ **Note**: This step can take several minutes depending on mesh complexity and number of views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63dd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] [CreateFromPointCloudAlphaShape] invalid tetra in TetraMesh\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [CreateFromPointCloudAlphaShape] invalid tetra in TetraMesh\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [CreateFromPointCloudAlphaShape] invalid tetra in TetraMesh\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [CreateFromPointCloudAlphaShape] invalid tetra in TetraMesh\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [CreateFromPointCloudAlphaShape] invalid tetra in TetraMesh\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n",
      "✅ Re-mesh complete: meshes/oakink_beaker_decomp2_remesh.obj, meshes/oakink_bottle_decomp2_remesh.obj\n",
      "Source mesh vert: (9291, 3)\n",
      "Target mesh vert: (9083, 3)\n",
      "Input 3D point: [ 0.00886742 -0.04124315 -0.01754964]\n",
      "Closest vertex: 2297 (distance: 0.0042)\n",
      "Closest vertex coordinates: [ 0.00722481 -0.0373988  -0.0171679 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixiliu/miniforge3/envs/diff3f_copy2/lib/python3.10/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " 70%|█████████████████████▋         | 7/10 [00:16<00:06,  2.27s/it]"
     ]
    }
   ],
   "source": [
    "remesh = True\n",
    "\n",
    "if 1:\n",
    "    source_mesh_path = \"meshes/oakink_beaker_decomp2.obj\"\n",
    "    target_mesh_path = \"meshes/oakink_bottle_decomp2.obj\"\n",
    "    num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "    if remesh: \n",
    "        from utils import remesh_mesh_pair\n",
    "        source_mesh_path, target_mesh_path = remesh_mesh_pair(\n",
    "            source_mesh_path,\n",
    "            target_mesh_path,\n",
    "            num_points=10000,\n",
    "            alpha=0.005\n",
    "        )\n",
    "\n",
    "    \n",
    "    source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "    target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "    \n",
    "    print(\"Source mesh vert:\", source_mesh.vert.shape)\n",
    "    print(\"Target mesh vert:\", target_mesh.vert.shape)\n",
    "    \n",
    "    # Run the complete analysis pipeline\n",
    "    similarity_colors, raw_similarities, source_point_idx, closest_distance = run_point_similarity_analysis(\n",
    "        source_mesh=source_mesh,\n",
    "        target_mesh=target_mesh,\n",
    "        source_point_3d=p1,\n",
    "        device=device,\n",
    "        pipe=pipe,\n",
    "        dino_model=dino_model,\n",
    "        prompt=prompt,\n",
    "        num_views=num_views\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22229792-bcb8-4c15-a7f0-91cbbf35e9fd",
   "metadata": {},
   "source": [
    "# Multi point analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5a36e-0035-4f65-a4cc-3d4f03c272e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source mesh: 11799 vertices, 23334 faces\n",
      "Target mesh: 9041 vertices, 17850 faces\n",
      "Finding correspondences for 4 source points...\n",
      "Closest vertices to input 3D points:\n",
      "  Point 0: [ 0.00886742 -0.04124315 -0.01754964] -> Vertex 5589 (distance: 0.0100)\n",
      "  Point 1: [-0.01223545  0.0363251   0.00719686] -> Vertex 9138 (distance: 0.0116)\n",
      "  Point 2: [-0.01694481  0.03424783 -0.01735426] -> Vertex 2681 (distance: 0.0060)\n",
      "  Point 3: [-0.01596961  0.03464369 -0.02075735] -> Vertex 2717 (distance: 0.0053)\n",
      "Computing features for source mesh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 20/20 [00:53<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  521 . Copied features from nearest vertices.\n",
      "Time taken in mins:  0.9516005992889405\n",
      "Computing features for target mesh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████▋                          | 3/20 [00:07<00:41,  2.43s/it]"
     ]
    }
   ],
   "source": [
    "## NOTE: no difference between oakink_beaker_decomp2.obj and oakink_beaker_decomp.obj\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_bottle_decomp.obj\"\n",
    "\n",
    "source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "num_views = 20  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17bbb8-1d1e-47fe-9d0a-b6860838b73f",
   "metadata": {},
   "source": [
    "# A few more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361247f-0cfc-47a1-ab96-abe26713b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 10\n",
    "\n",
    "\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp2.obj\"\n",
    "target_mesh_path = \"meshes/oakink_mug_decomp2.obj\"\n",
    "source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1dc2de-b400-4b31-a4ce-6e58cd22e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4856f-da34-4640-8c4f-45781a33d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_mug_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "num_views = 4  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f2053-d251-4466-8bc8-a1d6eae46da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_mug_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4802b-62f9-41e7-bbc0-141194de93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_wineglass_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd635f8a-5c10-4006-9f36-d1e2ce15a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_wineglass_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 6  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e2cdd-3bfa-40c2-ba56-303c1f2f1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_bowl_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 8  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12161555-abc9-4448-969e-86eb9080e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_mug2_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c84e6-7ecd-43e2-8592-10d7853d7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_vase_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379b271-60e7-4f4a-9e0b-911ec5d3ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_jar_decomp.obj\"\n",
    "\n",
    "# source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")\n",
    "\n",
    "# Analysis parameters\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 10  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance, target_points_3d = run_multi_point_correspondence_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_points_3d=source_points_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "print(\"\\n target_points_3d = \\n\", target_points_3d)\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd540bc5-03d9-4488-b9bf-0b1183332c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f693f9b8",
   "metadata": {},
   "source": [
    "## 7. Analyze Results\n",
    "\n",
    "Let's examine the similarity scores and find the most similar regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d472d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar points on target mesh\n",
    "top_k = 10\n",
    "most_similar_indices = np.argsort(raw_similarities)[-top_k:][::-1]\n",
    "least_similar_indices = np.argsort(raw_similarities)[:top_k]\n",
    "\n",
    "print(f\"📊 Similarity Statistics:\")\n",
    "print(f\"- Min similarity: {raw_similarities.min():.4f}\")\n",
    "print(f\"- Max similarity: {raw_similarities.max():.4f}\")\n",
    "print(f\"- Mean similarity: {raw_similarities.mean():.4f}\")\n",
    "print(f\"- Std similarity: {raw_similarities.std():.4f}\")\n",
    "\n",
    "print(f\"\\n🔥 Top {top_k} most similar vertices on target mesh:\")\n",
    "for i, idx in enumerate(most_similar_indices):\n",
    "    print(f\"  {i+1:2d}. Vertex {idx:5d}: similarity = {raw_similarities[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n❄️  Bottom {top_k} least similar vertices on target mesh:\")\n",
    "for i, idx in enumerate(least_similar_indices):\n",
    "    print(f\"  {i+1:2d}. Vertex {idx:5d}: similarity = {raw_similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddfe71d",
   "metadata": {},
   "source": [
    "## 8. Visualize Similarity Distribution\n",
    "\n",
    "Plot the distribution of similarity scores to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Plot similarity distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(raw_similarities, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(raw_similarities.mean(), color='red', linestyle='--', label=f'Mean: {raw_similarities.mean():.3f}')\n",
    "plt.axvline(raw_similarities.max(), color='green', linestyle='--', label=f'Max: {raw_similarities.max():.3f}')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Similarity Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sorted(raw_similarities, reverse=True), linewidth=2)\n",
    "plt.xlabel('Vertex Rank (sorted by similarity)')\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.title('Similarity Scores (Ranked)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec786b",
   "metadata": {},
   "source": [
    "## 9. Interactive Visualization\n",
    "\n",
    "The main result visualization showing:\n",
    "- **Left**: Source mesh (gray) with the selected point highlighted in red\n",
    "- **Right**: Target mesh colored by similarity (warmer colors = more similar)\n",
    "\n",
    "You can interact with the 3D visualization to rotate and zoom the meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎨 Interactive Visualization:\")\n",
    "print(\"- Source mesh (left): Gray with red point showing the reference vertex\")\n",
    "print(\"- Target mesh (right): Colored by similarity (warmer colors = more similar)\")\n",
    "print(\"- Use mouse to rotate and zoom the 3D view\")\n",
    "\n",
    "# The visualization was already created by run_point_similarity_analysis\n",
    "# But let's create it again with custom colormap options\n",
    "visualize_point_similarity(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_point_idx=source_point_idx,\n",
    "    similarity_colors=similarity_colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4dff0",
   "metadata": {},
   "source": [
    "## 10. Experiment with Different Points\n",
    "\n",
    "Try analyzing different points on the source mesh to see how similarity patterns change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76965326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different source points\n",
    "# You can change these indices and re-run this cell\n",
    "experiment_points = [100, 500, 1500, 2000]  # Different vertex indices to try\n",
    "\n",
    "for point_idx in experiment_points:\n",
    "    if point_idx < len(source_mesh.vert):\n",
    "        print(f\"\\n🔬 Experimenting with source vertex {point_idx}...\")\n",
    "\n",
    "        # Quick analysis with fewer views for faster computation\n",
    "        exp_colors, exp_similarities = point_similarity_colormap(\n",
    "            device=device,\n",
    "            pipe=pipe,\n",
    "            dino_model=dino_model,\n",
    "            source_mesh=source_mesh,\n",
    "            target_mesh=target_mesh,\n",
    "            source_point_idx=point_idx,\n",
    "            prompt=prompt,\n",
    "            num_views=10  # Fewer views for quick experiment\n",
    "        )\n",
    "\n",
    "        # Show quick stats\n",
    "        top_match = np.argmax(exp_similarities)\n",
    "        print(f\"  Best match: vertex {top_match} (similarity: {exp_similarities[top_match]:.4f})\")\n",
    "\n",
    "        # Visualize\n",
    "        visualize_point_similarity(\n",
    "            source_mesh=source_mesh,\n",
    "            target_mesh=target_mesh,\n",
    "            source_point_idx=point_idx,\n",
    "            similarity_colors=exp_colors,\n",
    "            colormap='viridis'\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping vertex {point_idx} (mesh only has {len(source_mesh.vert)} vertices)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e136c9",
   "metadata": {},
   "source": [
    "## 11. Save Results (Optional)\n",
    "\n",
    "Save the similarity data for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474618dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to files\n",
    "output_prefix = f\"similarity_results_vertex_{source_point_idx}\"\n",
    "\n",
    "# Save similarity scores\n",
    "np.save(f\"{output_prefix}_similarities.npy\", raw_similarities)\n",
    "np.save(f\"{output_prefix}_colors.npy\", similarity_colors)\n",
    "\n",
    "# Save analysis summary\n",
    "summary = {\n",
    "    'source_mesh_path': source_mesh_path,\n",
    "    'target_mesh_path': target_mesh_path,\n",
    "    'source_point_idx': source_point_idx,\n",
    "    'prompt': prompt,\n",
    "    'num_views': num_views,\n",
    "    'min_similarity': float(raw_similarities.min()),\n",
    "    'max_similarity': float(raw_similarities.max()),\n",
    "    'mean_similarity': float(raw_similarities.mean()),\n",
    "    'std_similarity': float(raw_similarities.std()),\n",
    "    'top_matches': [int(idx) for idx in most_similar_indices[:5]]\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f\"{output_prefix}_summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✅ Results saved:\")\n",
    "print(f\"  - Similarities: {output_prefix}_similarities.npy\")\n",
    "print(f\"  - Colors: {output_prefix}_colors.npy\")\n",
    "print(f\"  - Summary: {output_prefix}_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f80cb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. ✅ Load and visualize 3D meshes\n",
    "2. ✅ Extract semantic features using diffusion + DINO models\n",
    "3. ✅ Compute similarity between a specific source point and all target vertices\n",
    "4. ✅ Visualize results with interactive 3D plots\n",
    "5. ✅ Analyze similarity distributions and find best matches\n",
    "6. ✅ Experiment with different source points\n",
    "7. ✅ Save results for future analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different mesh pairs\n",
    "- Experiment with different prompts\n",
    "- Adjust the number of views for quality vs. speed trade-offs\n",
    "- Use the saved similarity data for further analysis or applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diff3f_copy2)",
   "language": "python",
   "name": "diff3f_copy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
