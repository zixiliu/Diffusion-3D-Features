{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b155ea17",
   "metadata": {},
   "source": [
    "# Point-to-Mesh Similarity Analysis\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load two meshes\n",
    "2. Specify a particular point on the source mesh\n",
    "3. Color-map the target mesh based on similarity to that point\n",
    "\n",
    "The analysis uses diffusion features + DINO features to compute semantic similarity between mesh vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc6797",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930249c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diff3f import get_features_per_vertex\n",
    "from time import time\n",
    "from utils import convert_mesh_container_to_torch_mesh, cosine_similarity, double_plot, get_colors, generate_colors\n",
    "from dataloaders.mesh_container import MeshContainer\n",
    "from diffusion import init_pipe\n",
    "from dino import init_dino\n",
    "from functional_map import compute_surface_map\n",
    "import importlib\n",
    "import meshplot as mp\n",
    "from point_to_mesh_similarity import run_point_similarity_analysis, point_similarity_colormap, visualize_point_similarity\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91398f0c",
   "metadata": {},
   "source": [
    "## 2. Initialize Models\n",
    "\n",
    "This step loads the diffusion pipeline and DINO model for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394b3ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing diffusion pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixiliu/miniforge3/envs/diff3f/lib/python3.10/site-packages/diffusers/configuration_utils.py:239: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'unet_2d_condition.UNet2DConditionModel'>.load_config(...) followed by <class 'unet_2d_condition.UNet2DConditionModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d45a5e943b45e893907e6d7e2ef719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DINO model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/zixiliu/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing diffusion pipeline...\")\n",
    "pipe = init_pipe(device)\n",
    "\n",
    "print(\"Initializing DINO model...\")\n",
    "dino_model = init_dino(device)\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19f72e",
   "metadata": {},
   "source": [
    "## 3. Load Meshes\n",
    "\n",
    "Load your source and target meshes. You can modify the paths below to use your own meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc0c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source mesh: 11799 vertices, 23334 faces\n",
      "Target mesh: 9041 vertices, 17850 faces\n"
     ]
    }
   ],
   "source": [
    "# Mesh paths - modify these to use your own meshes\n",
    "source_mesh_path = \"meshes/oakink_beaker_decomp.obj\"\n",
    "target_mesh_path = \"meshes/oakink_bottle_decomp.obj\"\n",
    "\n",
    "source_mesh = MeshContainer().load_from_file(source_mesh_path)\n",
    "target_mesh = MeshContainer().load_from_file(target_mesh_path)\n",
    "\n",
    "\n",
    "print(f\"Source mesh: {len(source_mesh.vert)} vertices, {len(source_mesh.face)} faces\")\n",
    "print(f\"Target mesh: {len(target_mesh.vert)} vertices, {len(target_mesh.face)} faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6403ea",
   "metadata": {},
   "source": [
    "## 4. Preview Meshes\n",
    "\n",
    "Let's visualize the meshes before analysis to get familiar with their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebd9cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c31c0312d30462fa3783614aa2d9645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecd8d6bdc294076bc497bdc8c922ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: Source mesh | Right: Target mesh\n"
     ]
    }
   ],
   "source": [
    "# Preview the meshes side by side\n",
    "d = mp.subplot(source_mesh.vert, source_mesh.face, s=[2, 2, 0])\n",
    "mp.subplot(target_mesh.vert, target_mesh.face, s=[2, 2, 1], data=d)\n",
    "print(\"Left: Source mesh | Right: Target mesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354bd759",
   "metadata": {},
   "source": [
    "## 5. Configure Analysis Parameters\n",
    "\n",
    "Set up the parameters for the similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35136983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Configuration:\n",
      "- Source point vertex index: 1000\n",
      "- Text prompt: 'a beaker'\n",
      "- Number of views: 25\n"
     ]
    }
   ],
   "source": [
    "# Analysis parameters\n",
    "source_point_idx = 1000  # Choose any vertex index (0 to num_vertices-1)\n",
    "prompt = \"a beaker\"  # Text prompt for feature extraction\n",
    "num_views = 25  # Number of views for rendering (reduced for faster computation)\n",
    "\n",
    "# Validate the source point index\n",
    "if source_point_idx >= len(source_mesh.vert):\n",
    "    source_point_idx = len(source_mesh.vert) // 2  # Use middle vertex as fallback\n",
    "    print(f\"Adjusted source_point_idx to {source_point_idx} (mesh has {len(source_mesh.vert)} vertices)\")\n",
    "\n",
    "print(f\"\\nAnalysis Configuration:\")\n",
    "print(f\"- Source point vertex index: {source_point_idx}\")\n",
    "print(f\"- Text prompt: '{prompt}'\")\n",
    "print(f\"- Number of views: {num_views}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7dd12e",
   "metadata": {},
   "source": [
    "## 6. Run Similarity Analysis\n",
    "\n",
    "This is the main computation step. It will:\n",
    "1. Extract features for both meshes using multiple camera views\n",
    "2. Compute similarity between the specified source point and all target vertices\n",
    "3. Generate the visualization\n",
    "\n",
    "‚ö†Ô∏è **Note**: This step can take several minutes depending on mesh complexity and number of views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63dd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 3D point: [-0.00793887 -0.0099004  -0.02071472]\n",
      "Closest vertex: 7884 (distance: 0.0246)\n",
      "Closest vertex coordinates: [-0.02394004 -0.02855902 -0.02099047]\n",
      "Computing features for source mesh...\n",
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [01:17<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  39\n",
      "Copied features from nearest vertices\n",
      "Time taken in mins:  1.3644153475761414\n",
      "Computing features for target mesh...\n",
      "Rendering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [01:10<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing features:  233\n",
      "Copied features from nearest vertices\n",
      "Time taken in mins:  1.2309698939323426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38784ca0d0df45f9803c1bc7ae468a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e7774219ea4b02b3279ef80bc8d98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source point (red): vertex 7884\n",
      "Target mesh colored by similarity to source point\n",
      "Similarity range: 0.000 to 1.000\n",
      "\n",
      "‚úÖ Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_point_3d = np.array([-0.00793887, -0.0099004, -0.02071472])\n",
    "\n",
    "# Run the complete analysis pipeline\n",
    "similarity_colors, raw_similarities, source_point_idx, closest_distance = run_point_similarity_analysis(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_point_3d=source_point_3d,\n",
    "    device=device,\n",
    "    pipe=pipe,\n",
    "    dino_model=dino_model,\n",
    "    prompt=prompt,\n",
    "    num_views=num_views\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693f9b8",
   "metadata": {},
   "source": [
    "## 7. Analyze Results\n",
    "\n",
    "Let's examine the similarity scores and find the most similar regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d472d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar points on target mesh\n",
    "top_k = 10\n",
    "most_similar_indices = np.argsort(raw_similarities)[-top_k:][::-1]\n",
    "least_similar_indices = np.argsort(raw_similarities)[:top_k]\n",
    "\n",
    "print(f\"üìä Similarity Statistics:\")\n",
    "print(f\"- Min similarity: {raw_similarities.min():.4f}\")\n",
    "print(f\"- Max similarity: {raw_similarities.max():.4f}\")\n",
    "print(f\"- Mean similarity: {raw_similarities.mean():.4f}\")\n",
    "print(f\"- Std similarity: {raw_similarities.std():.4f}\")\n",
    "\n",
    "print(f\"\\nüî• Top {top_k} most similar vertices on target mesh:\")\n",
    "for i, idx in enumerate(most_similar_indices):\n",
    "    print(f\"  {i+1:2d}. Vertex {idx:5d}: similarity = {raw_similarities[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ùÑÔ∏è  Bottom {top_k} least similar vertices on target mesh:\")\n",
    "for i, idx in enumerate(least_similar_indices):\n",
    "    print(f\"  {i+1:2d}. Vertex {idx:5d}: similarity = {raw_similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddfe71d",
   "metadata": {},
   "source": [
    "## 8. Visualize Similarity Distribution\n",
    "\n",
    "Plot the distribution of similarity scores to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot similarity distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(raw_similarities, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(raw_similarities.mean(), color='red', linestyle='--', label=f'Mean: {raw_similarities.mean():.3f}')\n",
    "plt.axvline(raw_similarities.max(), color='green', linestyle='--', label=f'Max: {raw_similarities.max():.3f}')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Similarity Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sorted(raw_similarities, reverse=True), linewidth=2)\n",
    "plt.xlabel('Vertex Rank (sorted by similarity)')\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.title('Similarity Scores (Ranked)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec786b",
   "metadata": {},
   "source": [
    "## 9. Interactive Visualization\n",
    "\n",
    "The main result visualization showing:\n",
    "- **Left**: Source mesh (gray) with the selected point highlighted in red\n",
    "- **Right**: Target mesh colored by similarity (warmer colors = more similar)\n",
    "\n",
    "You can interact with the 3D visualization to rotate and zoom the meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Interactive Visualization:\")\n",
    "print(\"- Source mesh (left): Gray with red point showing the reference vertex\")\n",
    "print(\"- Target mesh (right): Colored by similarity (warmer colors = more similar)\")\n",
    "print(\"- Use mouse to rotate and zoom the 3D view\")\n",
    "\n",
    "# The visualization was already created by run_point_similarity_analysis\n",
    "# But let's create it again with custom colormap options\n",
    "visualize_point_similarity(\n",
    "    source_mesh=source_mesh,\n",
    "    target_mesh=target_mesh,\n",
    "    source_point_idx=source_point_idx,\n",
    "    similarity_colors=similarity_colors,\n",
    "    colormap='plasma'  # Try 'viridis', 'plasma', 'inferno', 'magma'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4dff0",
   "metadata": {},
   "source": [
    "## 10. Experiment with Different Points\n",
    "\n",
    "Try analyzing different points on the source mesh to see how similarity patterns change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76965326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different source points\n",
    "# You can change these indices and re-run this cell\n",
    "experiment_points = [100, 500, 1500, 2000]  # Different vertex indices to try\n",
    "\n",
    "for point_idx in experiment_points:\n",
    "    if point_idx < len(source_mesh.vert):\n",
    "        print(f\"\\nüî¨ Experimenting with source vertex {point_idx}...\")\n",
    "\n",
    "        # Quick analysis with fewer views for faster computation\n",
    "        exp_colors, exp_similarities = point_similarity_colormap(\n",
    "            device=device,\n",
    "            pipe=pipe,\n",
    "            dino_model=dino_model,\n",
    "            source_mesh=source_mesh,\n",
    "            target_mesh=target_mesh,\n",
    "            source_point_idx=point_idx,\n",
    "            prompt=prompt,\n",
    "            num_views=10  # Fewer views for quick experiment\n",
    "        )\n",
    "\n",
    "        # Show quick stats\n",
    "        top_match = np.argmax(exp_similarities)\n",
    "        print(f\"  Best match: vertex {top_match} (similarity: {exp_similarities[top_match]:.4f})\")\n",
    "\n",
    "        # Visualize\n",
    "        visualize_point_similarity(\n",
    "            source_mesh=source_mesh,\n",
    "            target_mesh=target_mesh,\n",
    "            source_point_idx=point_idx,\n",
    "            similarity_colors=exp_colors,\n",
    "            colormap='viridis'\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping vertex {point_idx} (mesh only has {len(source_mesh.vert)} vertices)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e136c9",
   "metadata": {},
   "source": [
    "## 11. Save Results (Optional)\n",
    "\n",
    "Save the similarity data for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474618dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to files\n",
    "output_prefix = f\"similarity_results_vertex_{source_point_idx}\"\n",
    "\n",
    "# Save similarity scores\n",
    "np.save(f\"{output_prefix}_similarities.npy\", raw_similarities)\n",
    "np.save(f\"{output_prefix}_colors.npy\", similarity_colors)\n",
    "\n",
    "# Save analysis summary\n",
    "summary = {\n",
    "    'source_mesh_path': source_mesh_path,\n",
    "    'target_mesh_path': target_mesh_path,\n",
    "    'source_point_idx': source_point_idx,\n",
    "    'prompt': prompt,\n",
    "    'num_views': num_views,\n",
    "    'min_similarity': float(raw_similarities.min()),\n",
    "    'max_similarity': float(raw_similarities.max()),\n",
    "    'mean_similarity': float(raw_similarities.mean()),\n",
    "    'std_similarity': float(raw_similarities.std()),\n",
    "    'top_matches': [int(idx) for idx in most_similar_indices[:5]]\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f\"{output_prefix}_summary.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved:\")\n",
    "print(f\"  - Similarities: {output_prefix}_similarities.npy\")\n",
    "print(f\"  - Colors: {output_prefix}_colors.npy\")\n",
    "print(f\"  - Summary: {output_prefix}_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f80cb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. ‚úÖ Load and visualize 3D meshes\n",
    "2. ‚úÖ Extract semantic features using diffusion + DINO models\n",
    "3. ‚úÖ Compute similarity between a specific source point and all target vertices\n",
    "4. ‚úÖ Visualize results with interactive 3D plots\n",
    "5. ‚úÖ Analyze similarity distributions and find best matches\n",
    "6. ‚úÖ Experiment with different source points\n",
    "7. ‚úÖ Save results for future analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different mesh pairs\n",
    "- Experiment with different prompts\n",
    "- Adjust the number of views for quality vs. speed trade-offs\n",
    "- Use the saved similarity data for further analysis or applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diff3f)",
   "language": "python",
   "name": "diff3f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
